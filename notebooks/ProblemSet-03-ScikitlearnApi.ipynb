{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11d51098",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e712d6f",
   "metadata": {},
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2f4537",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d6cb48",
   "metadata": {},
   "source": [
    "# Scikit-Learn\n",
    "\n",
    "This lab will test your knowledge of scikit-learn and your ability to perform basic tasks using this foundational library.\n",
    "\n",
    "You are welcome (and encouraged) to make use of the scikit-learn documention\n",
    "\n",
    "https://scikit-learn.org/stable/modules/classes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927b50c5",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "In this problem, we will implement a variety of sklearn estimators.\n",
    "\n",
    "## Part a)\n",
    "Implement a transformer which standardizes a dataset according to the following formula\n",
    "\n",
    "$$ X = \\frac{X - \\mu}{\\sigma}$$ Where $\\mu$ is the average and $\\sigma$ is the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c7106a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62a8886ef9c78ce807463d4e898f9697",
     "grade": false,
     "grade_id": "cell-b2723affb8d46bf3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "import pandas as pd\n",
    "from sklearn.utils.validation import check_X_y, check_array\n",
    "\n",
    "class StandardizerTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    # applies tranformation to feature matrix \n",
    "    def transform(self, x, y=''):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "        return x # return the transformed x (new data)\n",
    "    \n",
    "    # calculate the \"parameters\" or the mean and standard deviation:\n",
    "    def fit(self, x, y=''):\n",
    "     \n",
    "            \n",
    "    # YOUR CODE HERE    \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ce6cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "trial_df = [[1, 2, 3, 4, 2],\n",
    "[1,2,3,4,2],\n",
    "[0,0,0,0,0]]\n",
    "\n",
    "y = [[1],[2],[3]]\n",
    "\n",
    "trial_df\n",
    "\n",
    "\n",
    "st = StandardizerTransformer()\n",
    "model = st.fit(trial_df,y)\n",
    "print(model.mean_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64db77f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69f49af97bf2cd08d06c6557ee1638ca",
     "grade": true,
     "grade_id": "cell-ce9193b5205876cb",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "check_estimator(StandardizerTransformer())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dde9e8",
   "metadata": {},
   "source": [
    "## Part b)\n",
    "\n",
    "Implement a Regressor which predicts the average of the input values.  As we know this is not a very good model, we will set the poor score tag so that we can validate the model interface. \n",
    "\n",
    "Please note that just because this is not the greatest model, that does not mean it is not a useful one.  This model can provide a wonderful baseline with which to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4904b41",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63785440f3e34639ae5b35a8fcad0dff",
     "grade": false,
     "grade_id": "cell-633c278e6d0be1ce",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class MeanModel(BaseEstimator, RegressorMixin):\n",
    "    def _more_tags(self):\n",
    "        return dict(poor_score=True)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daac7ca8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5fe4796cd62a65310019201ceb63a80",
     "grade": true,
     "grade_id": "cell-3909c3c95082d781",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "check_estimator(MeanModel())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62494483",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "In this problem, we will explore some of the higher level constructs in sklearn.  Lets start by downloading the dataset from\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/2/adult\n",
    "\n",
    "which is known as the census income dataset (see `adult.names` after the downloading of the data for more info).  We can do this with the following python function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a6a1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/{}\"\n",
    "def download(url, filepath):\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with filepath.open('wb') as fp:\n",
    "            for chunk in r.iter_content():\n",
    "                fp.write(chunk)\n",
    "        \n",
    "def download_adult_data(ignore_cache=False):\n",
    "    data_path = Path('data')\n",
    "    data_path.mkdir(exist_ok=True)\n",
    "    files = ['adult.data', 'adult.names', 'adult.test']\n",
    "    for file_ in files:\n",
    "        filepath = data_path.joinpath(file_)\n",
    "        if not ignore_cache and filepath.is_file():\n",
    "            continue\n",
    "        download(URL.format(file_), filepath)\n",
    "    return [data_path.joinpath(f) for f in files]\n",
    "download_adult_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfe77ea",
   "metadata": {},
   "source": [
    "Now we will load the data into appropriate datastructure  for processing with scikit-learn.  We use use `pandas` as a tool to import data.  Our goal is not to rewrite useful libraries but to use the tools available in order to do some interesting data stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab7b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class Dataset:\n",
    "    X_train: np.array\n",
    "    y_train: np.array\n",
    "    X_test: np.array\n",
    "    y_test: np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff33b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def load_adult_data():\n",
    "    download_adult_data()\n",
    "    data = pd.read_csv(Path('data').joinpath('adult.data'), header=None).values\n",
    "    test_data = pd.read_csv(Path('data').joinpath('adult.test'), header=None, skiprows=1).values\n",
    "    return Dataset(\n",
    "        X_train=data[:, :-1],\n",
    "        y_train=data[:, -1],\n",
    "        X_test=test_data[:, :-1],\n",
    "        y_test=np.array([i.rstrip('.') for i in test_data[:, -1]])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0519de8f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e69b8a0b0c91eafbb1f433831ea5e385",
     "grade": false,
     "grade_id": "cell-5c37ca7dc4a5f2a6",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Now lets do some exploratory data analysis on this dataset. In particular, look at the following columns \n",
    "\n",
    "- age\n",
    "- workclass\n",
    "- education\n",
    "\n",
    "\n",
    "And answer the following questions (with supporting evidence):\n",
    "\n",
    "- Is there anything about this feature which may need to be \"engineered\" in order to make it more useful?\n",
    "- Do you think that this feature has any predictive power?  Does this make intuitive sense to you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d856eaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_adult_data()\n",
    "# age = 0, workclass = 1, education = 3. \n",
    "for i in range(10):\n",
    "    print(\"age =\", dataset.X_train[i][0], \n",
    "          \"workclass =\", dataset.X_train[i][1], \n",
    "          \"education =\", dataset.X_train[i][3])\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaab4f6",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "\n",
    "Now we will start to do some basic feature engineering and start building up a set of models.\n",
    "\n",
    "## Part a)\n",
    "\n",
    "First we will start with the education feature.  While education is a categorical variable in the dataset, we do not expect all categories to be completely orthognal.  Lets create a transformer which will take the education categories and collapse all education levels below HS-grad to a single value \"No-Degree\".  And yes, there is an education-number feature as well, however, we want to do some exercises to learn :)\n",
    "\n",
    "**NOTE**: Although coding standards and checking for correctness of transformations is important, we will be concerned here with only your output.  However, we will be testing edge cases, so make sure you are considering those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dc3422",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9423077567a44620b933ffd435756351",
     "grade": false,
     "grade_id": "cell-103eea76b61a5ba9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class EducationTransformer(BaseEstimator, TransformerMixin):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48116e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EducationTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def transform(self, x, y=''):\n",
    "        li = ['11th', '9th', '7th-8th', '12th', '1st-4th', '10th', '5th-6th', 'Preschool']\n",
    "        \n",
    "        for i in range(len(x)):\n",
    "                if x[i][3].strip() in li:\n",
    "                    x[i][3] = \"No-Degree\"\n",
    "                    \n",
    "        return x\n",
    "    \n",
    "    def fit(self, x, y=''):\n",
    "                    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ebbda9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "beadd678f71f3e7b78313a4a8bfca8d1",
     "grade": true,
     "grade_id": "cell-36abe3b1d7564f50",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "d = load_adult_data()\n",
    "\n",
    "transformed = EducationTransformer().fit_transform(d.X_train[:, 3:4])[:, 0]\n",
    "assert 'No-Degree' in set(transformed)\n",
    "assert '11th' not in set(transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb7f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test that it works\n",
    "for i in range(100):\n",
    "    print(d.X_train[i][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5ffe05",
   "metadata": {},
   "source": [
    "## Part b)\n",
    "\n",
    "Now its often the case that models will not handle features which are not numerical, we will learn more about this later in class, however, for this specific example, we can get an intuition by thinking about these education levels.  Many algorithms (for example linear regression) will require that we use numerical features.  However, if we use numerical features, we are making some implicit assumptions about the metric on this data, specifically the distance between values.  Lets take a simple example with the following data\n",
    "\n",
    "|shirt_color|\n",
    "|---|\n",
    "|red|\n",
    "|red|\n",
    "|blue|\n",
    "|green|\n",
    "\n",
    "In this case, we could numerically encode this as \n",
    "\n",
    "\n",
    "|shirt_color|\n",
    "|---|\n",
    "|1|\n",
    "|1|\n",
    "|2|\n",
    "|3|\n",
    "\n",
    "and use a regression on the data, however, this would imply that red is somehow closer than to blue than to green.  In other words, our assignment of labels will affect the output.  Instead, we can reshape the matrix like so\n",
    "\n",
    "|shirt_color_red|shirt_color_blue|shirt_color_green|\n",
    "|---|---|---|\n",
    "|1|0|0|\n",
    "|1|0|0|\n",
    "|0|1|0|\n",
    "|0|0|1|\n",
    "\n",
    "which removes the encoding issues.\n",
    "\n",
    "Use the `OneHotcoder` from the sklearn library to build a more complex transformer which uses your previous transformer and then applies the one hot encoding on top of it.\n",
    "\n",
    "There are two possible ways to do this, one is to use a higher order constructor like a `Pipeline` and the other is to use composition.  You can do either in principle but please use a `Pipeline` to do it here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2972cc0a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a7fc5e151224093aadd4e25fd2c1d3f",
     "grade": false,
     "grade_id": "cell-3af3cf5a4a46f81f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "education_pipe = Pipeline([\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c7feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "education_pipe = Pipeline([\n",
    "    \n",
    "    (\"education\", EducationTransformer()), \n",
    "    \n",
    "    (\"one hot coder\", OneHotEncoder(handle_unknown='ignore'))\n",
    "    \n",
    "])\n",
    "\n",
    "#education_pipe.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97a84f7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06681c090e60b8481d186b028f457d3a",
     "grade": true,
     "grade_id": "cell-4d88f6c40888206f",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "d = load_adult_data()\n",
    "\n",
    "transformed = education_pipe.fit_transform(d.X_train[:, 3:4])\n",
    "\n",
    "assert transformed.shape[0] == d.X_train.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f67a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "education_pipe.fit(d.X_train)\n",
    "\n",
    "for i in range(10):\n",
    "    print(i, \"=\", d.X_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d66133",
   "metadata": {},
   "source": [
    "## Part c)\n",
    "\n",
    "Now we can apply our transformer to the feature matrix by making use of the scikit-learn object `ColumnTransformer`.  Use this to build a transformer which operates directly on the input feature matrix. Additionally, in order to make the auto grading work, please ensure the following:\n",
    "\n",
    "- Please name your solution transformer `ct_education`.  \n",
    "- Please make sure to pass through the rest of the columns. (check the `passthrough` options in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00f3215",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d871d0c680c173f893d2acededc91f06",
     "grade": false,
     "grade_id": "cell-fd1313986df3f15d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct_education = None # Your column transformer here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f38757",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "37fc6c82c00a7c53e3a056df85ef7e99",
     "grade": true,
     "grade_id": "cell-40ba994f3191cc28",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "res = ct_education.fit_transform(d.X_train)\n",
    "\n",
    "assert res.shape[0] == d.X_train.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eae3a8c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9792f934edcfb212e0751fc3e0172f1d",
     "grade": false,
     "grade_id": "cell-24592c2305532eff",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Part d)\n",
    "\n",
    "Now fit a model using the following features:\n",
    "\n",
    "- your transformed education column\n",
    "- age\n",
    "- hours-per-week\n",
    "- capital-gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92f5874-9389-4376-9a26-3bc8b00d685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
